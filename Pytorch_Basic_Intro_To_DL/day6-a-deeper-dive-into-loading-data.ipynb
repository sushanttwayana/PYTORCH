{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8658162,"sourceType":"datasetVersion","datasetId":5187090},{"sourceId":72225152,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Using the TensorDataset class\n\nIn practice, loading your data into a PyTorch dataset will be one of the first steps you take in order to create and train a neural network with PyTorch.\n\nThe TensorDataset class is very helpful when your dataset can be loaded directly as a NumPy array. Recall that TensorDataset() can take one or more NumPy arrays as input.\n\nIn this exercise, you'll practice creating a PyTorch dataset using the TensorDataset class.\n\ntorch and numpy have already been imported for you, along with the TensorDataset class.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport pandas as pd\nfrom torch.utils.data import TensorDataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:59:34.355035Z","iopub.execute_input":"2024-06-10T16:59:34.356242Z","iopub.status.idle":"2024-06-10T16:59:34.361660Z","shell.execute_reply.started":"2024-06-10T16:59:34.356191Z","shell.execute_reply":"2024-06-10T16:59:34.360461Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset\n\nnp_features = np.array(np.random.rand(12, 8))\nnp_target = np.array(np.random.rand(12, 1))\n\n# Convert arrays to PyTorch tensors\ntorch_features = torch.tensor(np_features)\ntorch_target = torch.tensor(np_target)\n# Create a TensorDataset from two tensors\ndataset = TensorDataset(torch_features, torch_target)\n# dataset = TensorDataset(torch_features.float(), torch_target.float())\n\n# Return the last element of this dataset\nprint(dataset[-1])","metadata":{"execution":{"iopub.status.busy":"2024-06-10T16:53:46.748942Z","iopub.execute_input":"2024-06-10T16:53:46.749423Z","iopub.status.idle":"2024-06-10T16:53:46.841737Z","shell.execute_reply.started":"2024-06-10T16:53:46.749394Z","shell.execute_reply":"2024-06-10T16:53:46.840704Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(tensor([0.0244, 0.8569, 0.0847, 0.9896, 0.8408, 0.2973, 0.0486, 0.8533],\n       dtype=torch.float64), tensor([0.5312], dtype=torch.float64))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"TensorDataset is great to use when your dataset can be loaded from NumPy arrays (or converted to NumPy arrays). However, sometimes you need to code a custom dataset class. \n\n","metadata":{}},{"cell_type":"code","source":"dataframe = pd.DataFrame({\n    'ph': [7.0, 8.1, np.nan, 7.8],\n    'Sulfate': [300, 320, 330, np.inf],\n    'Solids': [20000, 21000, 22000, 23000],\n    'Conductivity': [400, 420, 430, 440],\n    'Chloramines': [3.1, 3.2, 3.3, 3.4],\n    'Turbidity': [4.0, 4.1, 4.2, 4.3],\n    'Hardness': [150, 160, 170, 180],\n    'Organic_carbon': [10, 11, 12, 13],\n    'Potability': [0, 1, 0, 1]\n})\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T17:07:17.235224Z","iopub.execute_input":"2024-06-10T17:07:17.236089Z","iopub.status.idle":"2024-06-10T17:07:17.244304Z","shell.execute_reply.started":"2024-06-10T17:07:17.236050Z","shell.execute_reply":"2024-06-10T17:07:17.243104Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Normalize the features\nfeatures = dataframe[['ph', 'Sulfate', 'Solids', 'Conductivity', 'Chloramines', 'Turbidity', 'Hardness', 'Organic_carbon']]\nfeatures = (features - features.mean()) / features.std()\n\n# Convert to PyTorch tensors\nfeatures_tensor = torch.tensor(features.to_numpy()).float()\ntarget_tensor = torch.tensor(dataframe['Potability'].to_numpy()).float()\n\n# Create a dataset from the two generated tensors\ndataset = TensorDataset(features_tensor, target_tensor)\n\n# Create a dataloader using the above dataset\ndataloader = DataLoader(dataset, shuffle=True, batch_size=2)\n\n# Create a model using the nn.Sequential API\nmodel = nn.Sequential(\n    nn.Linear(8, 16),  # Adjust the input dimension to 8 to match the features\n    nn.ReLU(),\n    nn.Linear(16, 1),\n    nn.Sigmoid()  # Sigmoid activation function to squash output values to [0, 1]\n)\n\n# Define loss function and optimizer\ncriterion = nn.BCELoss()  # Binary Cross-Entropy Loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n\n# Train the model\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    for features_batch, target_batch in dataloader:\n        # Forward pass\n        output = model(features_batch)\n        \n        # Debugging: print output values\n        print(f\"Output: {output.detach().numpy()}\")\n        \n        # Ensure target shape matches output\n        loss = criterion(output, target_batch.unsqueeze(1))\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# After training, let's print out the output of the trained model\noutput = model(features_tensor)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2024-06-10T17:08:14.399759Z","iopub.execute_input":"2024-06-10T17:08:14.400727Z","iopub.status.idle":"2024-06-10T17:08:14.445501Z","shell.execute_reply.started":"2024-06-10T17:08:14.400663Z","shell.execute_reply":"2024-06-10T17:08:14.444393Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Output: [[0.4731331 ]\n [0.45483366]]\nOutput: [[0.46132874]\n [0.49768358]]\nOutput: [[0.46951687]\n [0.49919876]]\nOutput: [[0.46271887]\n [0.45657685]]\nOutput: [[0.5022042 ]\n [0.45703876]]\nOutput: [[0.46380085]\n [0.46520767]]\nOutput: [[0.5044786]\n [0.4576963]]\nOutput: [[0.46440172]\n [0.4622614 ]]\nOutput: [[0.5064703]\n [0.4581445]]\nOutput: [[0.46491283]\n [0.45917076]]\nOutput: [[0.4650357 ]\n [0.45744115]]\nOutput: [[0.45845065]\n [0.5088982 ]]\nOutput: [[0.45377332]\n [0.4651148 ]]\nOutput: [[0.4585345]\n [0.5103406]]\nOutput: [[0.4586553]\n [0.5112361]]\nOutput: [[0.46570426]\n [0.44879502]]\nOutput: [[0.45899907]\n [0.51325816]]\nOutput: [[0.4662863 ]\n [0.44567487]]\nOutput: [[0.44397348]\n [0.4593102 ]]\nOutput: [[0.4666956]\n [0.5160333]]\ntensor([[0.4405],\n        [0.4596],\n        [0.4669],\n        [0.5169]], grad_fn=<SigmoidBackward0>)\n","output_type":"stream"}]}]}