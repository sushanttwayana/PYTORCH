{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8714800,"sourceType":"datasetVersion","datasetId":5228486}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generating sequences\n\nTo be able to train neural networks on sequential data, you need to pre-process it first. You'll chunk the data into inputs-target pairs, where the inputs are some number of consecutive data points and the target is the next data point.\n\nYour task is to define a function to do this called create_sequences(). As inputs, it will receive data stored in a DataFrame, df and seq_length, the length of the inputs. As outputs, it should return two NumPy arrays, one with input sequences and the other one with the corresponding targets.","metadata":{}},{"cell_type":"markdown","source":"* Iterate over the range of the number of data points minus the length of an input sequence.\n* Define the inputs x as the slice of df from the ith row to the i + seq_lengthth row and the column at index 1.\n* Define the target y as the slice of df at row index i + seq_length and the column at index 1.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import TensorDataset\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:51:17.934626Z","iopub.execute_input":"2024-06-19T17:51:17.935041Z","iopub.status.idle":"2024-06-19T17:51:17.940840Z","shell.execute_reply.started":"2024-06-19T17:51:17.935009Z","shell.execute_reply":"2024-06-19T17:51:17.939522Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/electricity-consumption/electricityConsumptionAndProductioction.csv/electricityConsumptionAndProductioction.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:03:28.424544Z","iopub.execute_input":"2024-06-19T17:03:28.425140Z","iopub.status.idle":"2024-06-19T17:03:28.564527Z","shell.execute_reply.started":"2024-06-19T17:03:28.425101Z","shell.execute_reply":"2024-06-19T17:03:28.563549Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:04:05.091909Z","iopub.execute_input":"2024-06-19T17:04:05.092284Z","iopub.status.idle":"2024-06-19T17:04:05.106200Z","shell.execute_reply.started":"2024-06-19T17:04:05.092255Z","shell.execute_reply":"2024-06-19T17:04:05.105126Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"              DateTime  Consumption  Production  Nuclear  Wind  Hydroelectric  \\\n0  2019-01-01 00:00:00         6352        6527     1395    79           1383   \n1  2019-01-01 01:00:00         6116        5701     1393    96           1112   \n2  2019-01-01 02:00:00         5873        5676     1393   142           1030   \n3  2019-01-01 03:00:00         5682        5603     1397   191            972   \n4  2019-01-01 04:00:00         5557        5454     1393   159            960   \n\n   Oil and Gas  Coal  Solar  Biomass  \n0         1896  1744      0       30  \n1         1429  1641      0       30  \n2         1465  1616      0       30  \n3         1455  1558      0       30  \n4         1454  1458      0       30  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>DateTime</th>\n      <th>Consumption</th>\n      <th>Production</th>\n      <th>Nuclear</th>\n      <th>Wind</th>\n      <th>Hydroelectric</th>\n      <th>Oil and Gas</th>\n      <th>Coal</th>\n      <th>Solar</th>\n      <th>Biomass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01 00:00:00</td>\n      <td>6352</td>\n      <td>6527</td>\n      <td>1395</td>\n      <td>79</td>\n      <td>1383</td>\n      <td>1896</td>\n      <td>1744</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-01 01:00:00</td>\n      <td>6116</td>\n      <td>5701</td>\n      <td>1393</td>\n      <td>96</td>\n      <td>1112</td>\n      <td>1429</td>\n      <td>1641</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-01 02:00:00</td>\n      <td>5873</td>\n      <td>5676</td>\n      <td>1393</td>\n      <td>142</td>\n      <td>1030</td>\n      <td>1465</td>\n      <td>1616</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-01 03:00:00</td>\n      <td>5682</td>\n      <td>5603</td>\n      <td>1397</td>\n      <td>191</td>\n      <td>972</td>\n      <td>1455</td>\n      <td>1558</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-01 04:00:00</td>\n      <td>5557</td>\n      <td>5454</td>\n      <td>1393</td>\n      <td>159</td>\n      <td>960</td>\n      <td>1454</td>\n      <td>1458</td>\n      <td>0</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Extract 'timestamp' and 'Consumption' columns\ndf = df[['DateTime', 'Consumption']]\ndf.columns = ['timestamp', 'consumption']\n\n# Convert 'timestamp' to datetime\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\ndf = df.set_index('timestamp')\n\n# Step 2: Resample the data to 1-hour intervals\ndf = df.resample('H').mean()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:05:15.552248Z","iopub.execute_input":"2024-06-19T17:05:15.553176Z","iopub.status.idle":"2024-06-19T17:05:15.604987Z","shell.execute_reply.started":"2024-06-19T17:05:15.553138Z","shell.execute_reply":"2024-06-19T17:05:15.604055Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/1322871363.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['timestamp'] = pd.to_datetime(df['timestamp'])\n/tmp/ipykernel_33/1322871363.py:10: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n  df = df.resample('H').mean()\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:05:40.653860Z","iopub.execute_input":"2024-06-19T17:05:40.654275Z","iopub.status.idle":"2024-06-19T17:05:40.668386Z","shell.execute_reply.started":"2024-06-19T17:05:40.654241Z","shell.execute_reply":"2024-06-19T17:05:40.667208Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                     consumption\ntimestamp                       \n2019-01-01 00:00:00       6352.0\n2019-01-01 01:00:00       6116.0\n2019-01-01 02:00:00       5873.0\n2019-01-01 03:00:00       5682.0\n2019-01-01 04:00:00       5557.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>consumption</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>6352.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 01:00:00</th>\n      <td>6116.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 02:00:00</th>\n      <td>5873.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 03:00:00</th>\n      <td>5682.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 04:00:00</th>\n      <td>5557.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:12:43.504555Z","iopub.execute_input":"2024-06-19T17:12:43.505778Z","iopub.status.idle":"2024-06-19T17:12:43.512446Z","shell.execute_reply.started":"2024-06-19T17:12:43.505737Z","shell.execute_reply":"2024-06-19T17:12:43.511298Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"46008"},"metadata":{}}]},{"cell_type":"code","source":"\n# Step 3: Split the data into training and testing sets\ntrain_data = df[:'2023-05-30']  # First three years (up to end of 2022)\ntest_data = df['2023-06-01':]   # Fourth year (starting from 2023)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:09:46.743557Z","iopub.execute_input":"2024-06-19T17:09:46.744000Z","iopub.status.idle":"2024-06-19T17:09:46.751545Z","shell.execute_reply.started":"2024-06-19T17:09:46.743957Z","shell.execute_reply":"2024-06-19T17:09:46.750329Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))\nprint(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:09:49.848873Z","iopub.execute_input":"2024-06-19T17:09:49.849287Z","iopub.status.idle":"2024-06-19T17:09:49.854998Z","shell.execute_reply.started":"2024-06-19T17:09:49.849254Z","shell.execute_reply":"2024-06-19T17:09:49.853916Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"38664\n7320\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:15:04.410703Z","iopub.execute_input":"2024-06-19T17:15:04.411627Z","iopub.status.idle":"2024-06-19T17:15:04.424523Z","shell.execute_reply.started":"2024-06-19T17:15:04.411594Z","shell.execute_reply":"2024-06-19T17:15:04.423294Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                     consumption\ntimestamp                       \n2019-01-01 00:00:00       6352.0\n2019-01-01 01:00:00       6116.0\n2019-01-01 02:00:00       5873.0\n2019-01-01 03:00:00       5682.0\n2019-01-01 04:00:00       5557.0\n...                          ...\n2023-05-30 19:00:00       6309.0\n2023-05-30 20:00:00       6411.0\n2023-05-30 21:00:00       6647.0\n2023-05-30 22:00:00       6283.0\n2023-05-30 23:00:00       5621.0\n\n[38664 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>consumption</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-01-01 00:00:00</th>\n      <td>6352.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 01:00:00</th>\n      <td>6116.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 02:00:00</th>\n      <td>5873.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 03:00:00</th>\n      <td>5682.0</td>\n    </tr>\n    <tr>\n      <th>2019-01-01 04:00:00</th>\n      <td>5557.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2023-05-30 19:00:00</th>\n      <td>6309.0</td>\n    </tr>\n    <tr>\n      <th>2023-05-30 20:00:00</th>\n      <td>6411.0</td>\n    </tr>\n    <tr>\n      <th>2023-05-30 21:00:00</th>\n      <td>6647.0</td>\n    </tr>\n    <tr>\n      <th>2023-05-30 22:00:00</th>\n      <td>6283.0</td>\n    </tr>\n    <tr>\n      <th>2023-05-30 23:00:00</th>\n      <td>5621.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>38664 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test_data","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:09:53.070284Z","iopub.execute_input":"2024-06-19T17:09:53.071224Z","iopub.status.idle":"2024-06-19T17:09:53.083454Z","shell.execute_reply.started":"2024-06-19T17:09:53.071187Z","shell.execute_reply":"2024-06-19T17:09:53.082086Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                     consumption\ntimestamp                       \n2023-06-01 00:00:00       5136.0\n2023-06-01 01:00:00       4943.0\n2023-06-01 02:00:00       4778.0\n2023-06-01 03:00:00       4726.0\n2023-06-01 04:00:00       4701.0\n...                          ...\n2024-03-31 19:00:00       5618.0\n2024-03-31 20:00:00       6107.0\n2024-03-31 21:00:00       5991.0\n2024-03-31 22:00:00       5527.0\n2024-03-31 23:00:00       5111.0\n\n[7320 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>consumption</th>\n    </tr>\n    <tr>\n      <th>timestamp</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2023-06-01 00:00:00</th>\n      <td>5136.0</td>\n    </tr>\n    <tr>\n      <th>2023-06-01 01:00:00</th>\n      <td>4943.0</td>\n    </tr>\n    <tr>\n      <th>2023-06-01 02:00:00</th>\n      <td>4778.0</td>\n    </tr>\n    <tr>\n      <th>2023-06-01 03:00:00</th>\n      <td>4726.0</td>\n    </tr>\n    <tr>\n      <th>2023-06-01 04:00:00</th>\n      <td>4701.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2024-03-31 19:00:00</th>\n      <td>5618.0</td>\n    </tr>\n    <tr>\n      <th>2024-03-31 20:00:00</th>\n      <td>6107.0</td>\n    </tr>\n    <tr>\n      <th>2024-03-31 21:00:00</th>\n      <td>5991.0</td>\n    </tr>\n    <tr>\n      <th>2024-03-31 22:00:00</th>\n      <td>5527.0</td>\n    </tr>\n    <tr>\n      <th>2024-03-31 23:00:00</th>\n      <td>5111.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7320 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:10:57.960791Z","iopub.execute_input":"2024-06-19T17:10:57.961525Z","iopub.status.idle":"2024-06-19T17:10:57.968980Z","shell.execute_reply.started":"2024-06-19T17:10:57.961491Z","shell.execute_reply":"2024-06-19T17:10:57.967483Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(38664, 1)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Sequential Dataset**\n\nGood job building the create_sequences() function! It's time to use it to create a training dataset for your model.\n\nJust like tabular and image data, sequential data is easiest passed to a model through a torch Dataset and DataLoader. To build a sequential Dataset, you will call create_sequences() to get the NumPy arrays with inputs and targets, and inspect their shape. Next, you will pass them to a TensorDataset to create a proper torch Dataset, and inspect its length.\n\nYour implementation of create_sequences() and a DataFrame with the training data called train_data are available.\n\nCall create_sequences(), passing it the training DataFrame and a sequence length of 24*4, assigning the result to X_train, y_train.\nDefine dataset_train by calling TensorDataset and passing it two arguments, the inputs and the targets created by create_sequences(), both converted from NumPy arrays to tensors of floats.","metadata":{}},{"cell_type":"code","source":"def create_sequences(df, seq_length):\n    xs, ys = [], []\n    # Iterate over data indices\n    for i in range(len(df) - seq_length):\n      \t# Define inputs\n        x = df.iloc[i:(i + seq_length), 0]\n        # Define target\n        y = df.iloc[i + seq_length, 0]\n        xs.append(x)\n        ys.append(y)\n    return np.array(xs), np.array(ys)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T17:16:19.889806Z","iopub.execute_input":"2024-06-19T17:16:19.890258Z","iopub.status.idle":"2024-06-19T17:16:19.897234Z","shell.execute_reply.started":"2024-06-19T17:16:19.890224Z","shell.execute_reply":"2024-06-19T17:16:19.896027Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"You can now use create_sequences() to create a set of training or testing examples for the model, where each example consists of an input of seq_length consecutive data points, and the single target, the following data point. ","metadata":{}},{"cell_type":"code","source":"# Define sequence length: 24 hours\nseq_length = 24 * 24\n\n# Use create_sequences to create inputs and targets for training data\nX_train, y_train = create_sequences(train_data, seq_length)\nprint(X_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:16:23.125475Z","iopub.execute_input":"2024-06-19T17:16:23.125870Z","iopub.status.idle":"2024-06-19T17:16:32.693358Z","shell.execute_reply.started":"2024-06-19T17:16:23.125840Z","shell.execute_reply":"2024-06-19T17:16:32.692206Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(38088, 576) (38088,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As you can see from the printed output, we have 38088 training examples, each consisting of 576 inputs and 1 target value. The TensorDataset you have just built behaves the same way as other Torch Datasets you have used before, such us our custom WaterDataset or the ImageFolder dataset; you can pass it to a DataLoader in the same way. With the sequential data ready, let's take a look at model architectures suitable for processing sequential data!","metadata":{}},{"cell_type":"markdown","source":"# Building a forecasting RNN\n\nIt's time to build your first recurrent network! It will be a sequence-to-vector model consisting of an RNN layer with two layers and a hidden_size of 32. After the RNN layer, a simple linear layer will map the outputs to a single value to be predicted.","metadata":{}},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Define RNN layer\n        self.rnn = nn.RNN(\n            input_size=1,\n            hidden_size=32,\n            num_layers=2,\n            batch_first=True,\n        )\n        self.fc = nn.Linear(32, 1)\n\n    def forward(self, x):\n        # Initialize first hidden state with zeros\n        h0 = torch.zeros(2, x.size(0), 32)\n        # Pass x and h0 through recurrent layer\n        out, _ = self.rnn(x, h0)  \n        # Pass recurrent layer's last output through linear layer\n        out = self.fc(out[:, -1, :])\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-06-19T17:51:22.775697Z","iopub.execute_input":"2024-06-19T17:51:22.776092Z","iopub.status.idle":"2024-06-19T17:51:22.786047Z","shell.execute_reply.started":"2024-06-19T17:51:22.776063Z","shell.execute_reply":"2024-06-19T17:51:22.784615Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}